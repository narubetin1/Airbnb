import streamlit as st
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression
from xgboost import XGBRegressor
from sklearn.cluster import KMeans # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ KMeans ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°
import warnings
warnings.filterwarnings("ignore")
from pymongo import MongoClient

#MongoDB
DB_NAME  = "airbnb_db"
COLLECTION_NAME = "listings"

URI = 'mongodb+srv://Pha22:Pha22@cluster0.okkqifc.mongodb.net/'
client = MongoClient(URI)
collection = client[DB_NAME][COLLECTION_NAME]

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö Streamlit
st.set_page_config(page_title="üìà ML Airbnb Price Prediction", layout="wide") 
st.title("ü§ñ Airbnb Price Prediction (Feature Selection)") 

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ @st.cache_data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Ñ‡∏ä‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
@st.cache_data
def load_data():
    #df = pd.read_csv("080668one_hot_amenities_1.csv")
    df = pd.DataFrame(list(collection.find()))

    # ‡∏•‡∏ö _id ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ
    if "_id" in df.columns:
        df.drop(columns=["_id"], inplace=True)
    df['price'] = df['price'].replace('[\$,]', '', regex=True).astype(float) # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏≤‡∏Ñ‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    df['instant_bookable'] = df['instant_bookable'].map({'t': True, 'f': False}) # ‡πÅ‡∏õ‡∏•‡∏á 't'/'f' ‡πÄ‡∏õ‡πá‡∏ô True/False
    df['host_is_superhost'] = df['host_is_superhost'].map({'t': True, 'f': False}) # ‡πÅ‡∏õ‡∏•‡∏á 't'/'f' ‡πÄ‡∏õ‡πá‡∏ô True/False
    df['room_type'] = df['room_type'].str.strip().str.lower().str.title() # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏´‡πâ‡∏≠‡∏á‡∏û‡∏±‡∏Å
    df['property_type'] = df['property_type'].astype(str).str.strip().str.title() # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏Å
    df.fillna(0, inplace=True) # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (NaN) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏î‡πâ‡∏ß‡∏¢ 0
    df['amenities_count'] = df.iloc[:, 32:66].sum(axis=1) # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 0/1)
    if 'property_type' in df.columns:
        conditions = [
        df['property_type'].str.lower().str.contains('apartment', na=False),
        df['property_type'].str.lower().str.contains('house', na=False),
        df['property_type'].str.lower().str.contains('condominium', na=False) | df['property_type'].str.lower().str.contains('condo', na=False),
        df['property_type'].str.lower().str.contains('hotel', na=False),
        df['property_type'].str.lower().str.contains('hostel', na=False)
        ]   
    choices = ['Apartment', 'House', 'Condo', 'Hotel', 'Hostel']
    df['property_grouped'] = np.select(conditions, choices, default='Other')
    return df

def remove_outliers_grouped(df, target_col='price'):
    def iqr_filter(group):
        q1 = group[target_col].quantile(0.25)
        q3 = group[target_col].quantile(0.75)
        iqr = q3 - q1
        lower = q1 - 1.5 * iqr
        upper = q3 + 1.5 * iqr
        return group[(group[target_col] >= lower) & (group[target_col] <= upper)]
    
    return df.groupby(['neighbourhood', 'room_type', 'property_grouped', 'bedrooms'], group_keys=False).apply(iqr_filter)

df_raw = load_data()
df = remove_outliers_grouped(df_raw)
amenity_cols = ["Air conditioning", "Bed linens", "Breakfast", "Coffee maker", "Dedicated workspace",
    "Dishes and silverware", "Dryer", "Elevator", "Essentials", "Extra pillows and blankets",
    "Fire extinguisher", "First aid kit", "Free parking", "Garden or backyard", "Gym",
    "Hair dryer", "Hangers", "Heating", "Host greets you", "Hot water", "Iron", "Kitchen",
    "Lock on bedroom door", "Lockbox", "Luggage dropoff allowed", "Microwave",
    "Patio or balcony", "Pool", "Refrigerator", "Room-darkening shades", "Shampoo",
    "Shower gel", "Smoke alarm", "TV", "Washer", "Wifi"] # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (UI) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
st.subheader("üìå Input for Prediction")
selected_neighbourhood = st.selectbox("Select Neighborhood:", sorted(df['neighbourhood'].dropna().unique()))
selected_room_type = st.selectbox("Select Room Type:", sorted(df['room_type'].dropna().unique()))
selected_property_grouped = st.selectbox("Select Property:", sorted(df['property_grouped'].dropna().unique()))
selected_bedrooms = st.number_input("Number of Bedrooms:", min_value=0, value=1)
min_nights = st.number_input("Minimum Nights:", min_value=1, value=1)

st.markdown("**Select Amenities:**")
select_all = st.checkbox("Select All")
selected_amenities = []
amenity_col1, amenity_col2 = st.columns(2)
with amenity_col1:
    for i, col in enumerate(amenity_cols[:len(amenity_cols)//2]):
        checked = st.checkbox(col.replace('_', ' ').title(), key=f"amenity1_{i}", value=select_all)
        if checked:
            selected_amenities.append(col)
with amenity_col2:
    for i, col in enumerate(amenity_cols[len(amenity_cols)//2:]):
        checked = st.checkbox(col.replace('_', ' ').title(), key=f"amenity2_{i}", value=select_all)
        if checked:
            selected_amenities.append(col)

# --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Feature Selection ---
# ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å)
base_cols = [
    'neighbourhood', 'room_type', 'property_grouped', 'bedrooms',
    'minimum_nights', 'instant_bookable', 'host_is_superhost', 'amenities_count'
]
used_cols = base_cols + list(amenity_cols) # ‡∏£‡∏ß‡∏°‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏¥‡πà‡∏á‡∏≠‡∏≥‡∏ô‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å
X_raw = df[used_cols] # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏î‡∏¥‡∏ö
y = df['price'] # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (‡∏£‡∏≤‡∏Ñ‡∏≤)

# ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (Categorical) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (Numeric)
categorical_cols = ['neighbourhood', 'room_type', 'property_grouped']
numeric_cols = [c for c in used_cols if c not in categorical_cols]

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Dummy Variables ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏±‡∏î‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå
X_dummy = pd.get_dummies(X_raw, columns=categorical_cols, drop_first=True) # ‡∏ó‡∏≥ One-hot encoding ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
X_dummy = X_dummy.fillna(0) # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏ó‡∏≥ dummy variables
selector = VarianceThreshold(threshold=0.01) # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå
X_sel = selector.fit_transform(X_dummy)
feat_var = X_dummy.columns[selector.get_support()] # ‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô VarianceThreshold

k = min(25, len(feat_var)) # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 25)
kbest = SelectKBest(f_regression, k=k) # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å K ‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏£‡∏≤‡∏Ñ‡∏≤
X_k = kbest.fit_transform(X_dummy[feat_var], y)
feat_selected = feat_var[kbest.get_support()] # ‡∏ä‡∏∑‡πà‡∏≠‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•

st.write("üîé **Features used for training:**", list(feat_selected))

# --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Dictionary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Input ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ---
input_dict = {
    'bedrooms': [selected_bedrooms],
    'minimum_nights': [min_nights],
    'instant_bookable': [True],
    'host_is_superhost': [False],
    'amenities_count': [len(selected_amenities)],
}
for col in amenity_cols:
    input_dict[col] = [1 if col in selected_amenities else 0]

# ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Dummy Variables ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (Categorical)
for c in categorical_cols:
    # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å UI ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡πâ‡∏î
    if c == 'neighbourhood':
        selected_val = selected_neighbourhood
    elif c == 'room_type':
        selected_val = selected_room_type
    elif c == 'property_grouped':
        selected_val = selected_property_grouped
    else:
        selected_val = None # ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö categorical_cols ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ

    for v in df[c].dropna().unique():
        col_name_dummy = f"{c}_{v}"
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Dummy Variable ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏≤‡∏Å‡∏è‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô feat_selected
        if col_name_dummy in feat_selected:
            input_dict[col_name_dummy] = [1 if (selected_val == v) else 0]
        else:
            input_dict[col_name_dummy] = [0] # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ô feat_selected

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô feat_selected ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô input_dict (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° 0)
for col in feat_selected:
    if col not in input_dict:
        input_dict[col] = [0]

input_df = pd.DataFrame(input_dict)

# ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡∏≠‡∏á input_df ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô feat_selected
input_df = input_df.reindex(columns=feat_selected, fill_value=0)
X_train = X_dummy[feat_selected] # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß)

# --- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å (Train) ---
model_choice = st.selectbox("Select Model:", ["Random Forest", "Linear Regression", "Decision Tree", "XGBoost"])

# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô Hyperparameters
st.subheader("‚öôÔ∏è Hyperparameter Tuning")
perform_tuning = st.checkbox("Perform Hyperparameter Tuning (may take time)")

if st.button("üöÄ Predict Price"):
    with st.spinner("Processing..."): 
        model_to_fit = None # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô

        if model_choice == "Random Forest":
            if perform_tuning:
                st.write("Tuning Random Forest Regressor...") 
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Hyperparameter Grid ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GridSearchCV
                param_grid = {
                    'n_estimators': [50, 100, 150], # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ
                    'max_depth': [5, 8, 10, None], # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ (None ‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)
                    'min_samples_split': [2, 5], # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡πà‡∏á‡πÇ‡∏´‡∏ô‡∏î
                    'min_samples_leaf': [1, 2] # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô‡πÉ‡∏ö
                }
                # ‡πÉ‡∏ä‡πâ GridSearchCV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Hyperparameters ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                grid_search = GridSearchCV(
                    estimator=RandomForestRegressor(random_state=42),
                    param_grid=param_grid,
                    cv=3, # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Ç‡∏≠‡∏á cross-validation
                    scoring='neg_mean_absolute_error', # ‡πÉ‡∏ä‡πâ MAE (‡∏Ñ‡πà‡∏≤‡∏•‡∏ö)
                    n_jobs=-1, # ‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å core ‡∏Ç‡∏≠‡∏á CPU
                    verbose=1 # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
                )
                grid_search.fit(X_train, y)
                model_to_fit = grid_search.best_estimator_
                st.write(f"Random Forest Best Hyperparameters: {grid_search.best_params_}")
            else:
                model_to_fit = RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42)

        elif model_choice == "Decision Tree":
            if perform_tuning:
                st.write("Tuning Decision Tree Regressor...") 
                param_grid = {
                    'max_depth': [3, 5, 7, 10, None],
                    'min_samples_split': [2, 5, 10],
                    'min_samples_leaf': [1, 3, 5]
                }
                grid_search = GridSearchCV(
                    estimator=DecisionTreeRegressor(random_state=42),
                    param_grid=param_grid,
                    cv=3,
                    scoring='neg_mean_absolute_error',
                    n_jobs=-1,
                    verbose=1
                )
                grid_search.fit(X_train, y)
                model_to_fit = grid_search.best_estimator_
                st.write(f"Decision Tree Best Hyperparameters: {grid_search.best_params_}")
            else:
                model_to_fit = DecisionTreeRegressor(max_depth=6, random_state=42)

        elif model_choice == "XGBoost":
            if perform_tuning:
                st.write("Tuning XGBoost Regressor...") 
                # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å XGBoost ‡∏°‡∏µ Hyperparameters ‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏à‡∏π‡∏ô‡∏ô‡∏≤‡∏ô
                # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ RandomizedSearchCV ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
                # ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î param_grid ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏•‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GridSearchCV
                param_distributions = {
                    'n_estimators': [100, 200, 300],
                    'max_depth': [3, 5, 7],
                    'learning_rate': [0.01, 0.05, 0.1, 0.15],
                    'subsample': [0.7, 0.8, 0.9],
                    'colsample_bytree': [0.7, 0.8, 0.9],
                    'gamma': [0, 0.1, 0.2]
                }
                # ‡πÉ‡∏ä‡πâ RandomizedSearchCV ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÉ‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏ß‡πà‡∏≤
                random_search = RandomizedSearchCV(
                    estimator=XGBRegressor(objective='reg:squarederror', random_state=42),
                    param_distributions=param_distributions,
                    n_iter=20, # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á (‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß)
                    cv=3,
                    scoring='neg_mean_absolute_error',
                    n_jobs=-1,
                    verbose=1,
                    random_state=42
                )
                random_search.fit(X_train, y)
                model_to_fit = random_search.best_estimator_
                st.write(f"XGBoost Best Hyperparameters: {random_search.best_params_}")
            else:
                model_to_fit = XGBRegressor(n_estimators=50, max_depth=4, learning_rate=0.15, objective='reg:squarederror', random_state=42)
        else: # Linear Regression ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô Hyperparameters ‡∏°‡∏≤‡∏Å‡∏ô‡∏±‡∏Å
            model_to_fit = LinearRegression()
            if perform_tuning:
                st.warning("Linear Regression does not significantly benefit from hyperparameter tuning.") 


        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        if model_to_fit is None:
            st.error("Error: Could not create model. Please select a model and retry.") 
            st.stop() # ‡πÉ‡∏ä‡πâ st.stop() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡πÉ‡∏ô Streamlit

        # ‡∏ó‡∏≥ Cross-Validation ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ
        scores = cross_val_score(model_to_fit, X_train, y, cv=3, scoring='neg_mean_absolute_error')
        mae = -np.mean(scores)
        model_to_fit.fit(X_train, y) # ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        pred_price = model_to_fit.predict(input_df)[0]

        if perform_tuning:
            st.info("üí° Model has been hyperparameter tuned.") 

        st.success(f"‚úÖ Predicted Price: {pred_price:,.0f} Baht/Night") 
        st.info(f"MAE from Cross-Validation: {mae:,.2f} Baht") 

        # --- ‡πÄ‡∏û‡∏¥‡πà‡∏° Metric: RMSE ‡πÅ‡∏•‡∏∞ R¬≤ ---
        from sklearn.metrics import mean_squared_error, r2_score

        # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏î‡∏ú‡∏•
        y_pred_all = model_to_fit.predict(X_train)

        rmse = np.sqrt(mean_squared_error(y, y_pred_all))
        r2 = r2_score(y, y_pred_all)

        st.info(f"RMSE on Training Data: {rmse:,.2f} Baht")
        st.info(f"R¬≤ on Training Data: {r2:.4f}")

        # --- ‡∏™‡πà‡∏ß‡∏ô Clustering ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Neighbourhood ---
        df_cluster = df[df['neighbourhood'] == selected_neighbourhood][used_cols].copy()
        df_cluster['price'] = df[df['neighbourhood'] == selected_neighbourhood]['price']

        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Input ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
        temp_input_cluster = pd.DataFrame(columns=used_cols)
        temp_input_cluster.loc[0, 'bedrooms'] = selected_bedrooms
        temp_input_cluster.loc[0, 'minimum_nights'] = min_nights
        temp_input_cluster.loc[0, 'instant_bookable'] = True
        temp_input_cluster.loc[0, 'host_is_superhost'] = False
        temp_input_cluster.loc[0, 'amenities_count'] = len(selected_amenities)
        temp_input_cluster.loc[0, 'neighbourhood'] = selected_neighbourhood
        temp_input_cluster.loc[0, 'room_type'] = selected_room_type
        temp_input_cluster.loc[0, 'property_grouped'] = selected_property_grouped
        for col in amenity_cols:
            temp_input_cluster.loc[0, col] = 1 if col in selected_amenities else 0
        temp_input_cluster['price'] = pred_price

        # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        combined_df = pd.concat([df_cluster, temp_input_cluster], ignore_index=True).fillna(0)

        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Clustering
        cluster_pre = ColumnTransformer([
            ("cat", OneHotEncoder(handle_unknown='ignore'), categorical_cols)
        ], remainder='passthrough')

        X_cluster = cluster_pre.fit_transform(combined_df)
        scaler = StandardScaler(with_mean=False)
        X_scaled = scaler.fit_transform(X_cluster)

        # ‡∏´‡∏≤ optimal k
        sse = []
        for k in range(2, 10):
            km = KMeans(n_clusters=k, random_state=42, n_init=10)
            km.fit(X_scaled)
            sse.append(km.inertia_)

        optimal_k = sse.index(min(sse)) + 2 if len(sse) >= 2 else 2
        

        # ‡∏ó‡∏≥ KMeans
        kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
        cluster_labels = kmeans.fit_predict(X_scaled)
        combined_df['cluster'] = cluster_labels

        input_cluster_label = combined_df.iloc[-1]['cluster']
        df_cluster['cluster'] = cluster_labels[:len(df_cluster)]

        # ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á
        competitors = df_cluster[df_cluster['cluster'] == input_cluster_label].copy()
        competitors['price'] = df.loc[competitors.index, 'price']
        competitors['name'] = df.loc[competitors.index, 'name']

        st.subheader("üèÅ Competitors in the Same Cluster")
        st.write(f"üîç Filtering competitors only in neighbourhood: `{selected_neighbourhood}`")
        st.info(f"üî¢ Optimal number of clusters (K): {optimal_k}")
        st.dataframe(competitors[['name', 'neighbourhood', 'room_type', 'property_grouped', 'bedrooms', 'price']].reset_index(drop=True))
 
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏∏‡πà‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Export ‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        @st.cache_data
        def convert_df_to_csv(df_to_convert):
            # IMPORTANT: Cache the conversion to prevent computation on every rerun
            return df_to_convert.to_csv(index=False).encode('utf-8')

        csv = convert_df_to_csv(competitors[['name', 'neighbourhood', 'room_type', 'property_grouped', 'bedrooms', 'price']].reset_index(drop=True))

        st.download_button(
            label="Download Competitors as CSV",
            data=csv,
            file_name='airbnb_competitors.csv',
            mime='text/csv',
        )